{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f85595",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-36c1aa7bac5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "@author Andrea Corriga\n",
    "@contact me@andreacorriga.com\n",
    "@date 2018\n",
    "@version 1.0\n",
    "'''\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Import my alghorithms\n",
    "from algorithms.LBP import LBP\n",
    "# Import my utils method\n",
    "from utils.utils import *\n",
    "from utils.dataset import *\n",
    "\n",
    "from sklearn.metrics import accuracy_score #c alculate accuracy\n",
    "from sklearn.externals import joblib # save and load model\n",
    "from sklearn.model_selection import train_test_split # in order to split training and test\n",
    "import numpy\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "def main():\n",
    "\n",
    "\tparser = argparse.ArgumentParser(description='')\n",
    "\tparser.add_argument('--dataset', dest='dataset', type=str, default='YaleFaces', help='Main folder of the dataset')\n",
    "\tparser.add_argument('--classifier', dest='classifier', type=str, default='svm', help='Classifier to use: \"svm\" or \"naivebayes\" or \"knn\"')\n",
    "\tparser.add_argument('--training', dest='training', action='store_true', default=False, help='whether or not an output image should be produced')\n",
    "\tparser.add_argument('--histEq', dest='histEq', action='store_true', default=False, help='if you want to equialize the histogram before calculating LBP')\n",
    "\tparser.add_argument('--output', dest='output', action='store_true', default=False, help='if you want to save the png of LBP image')\n",
    "\n",
    "\targuments = parser.parse_args()\n",
    "\tdatasetMainFolder = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "\t# Security check about the classifier\n",
    "\tif(arguments.classifier != \"svm\" and arguments.classifier != \"naivebayes\" and arguments.classifier != \"knn\"):\n",
    "\t\tprint(\"Classifier not valid. Choose between svm, naivebayes or knn\")\n",
    "\t\treturn\n",
    "\n",
    "\t# Security check about the dataset\n",
    "\tif os.path.isdir(datasetMainFolder + arguments.dataset) == False:\n",
    "\t\tprint('The Dataset \"' + arguments.dataset + '\" doesn\\'t exist')\n",
    "\t\treturn\n",
    "\n",
    "\t# Helpful instad of write datasetMainFolder + arguments.dataset + \"/\"\n",
    "\tdatasetFolder = datasetMainFolder + arguments.dataset + \"/\"\n",
    "\n",
    "\t# Get Dataset information\n",
    "\tclasses, filenames, xFilepaths, y = getDataset(arguments.dataset)\n",
    "\tx = []\n",
    "\n",
    "\tprint(\"Launching LBP on the \" + arguments.dataset + \" dataset...\")\n",
    "\tstartTime = time.time()\n",
    "\n",
    "\t# This counter is used to store the png \n",
    "\tcounter = 0\n",
    "\n",
    "\t# if --output is passed as parameter\n",
    "\tif arguments.output == True:\n",
    "\t\tcreateFolderLBP(arguments.dataset, \"LBP\" )\n",
    "\n",
    "\n",
    "\tfor xfp in xFilepaths:\n",
    "\t\timg = imgRead(datasetFolder + xfp)\n",
    "\n",
    "\t\t#imgShow(numpy.matrix(img))\n",
    "\n",
    "\t\t# Check if img exist (security check)\n",
    "\t\tif img:\n",
    "\t\t\t# if --histEq is passed as parameter, perform an histogram equalization\n",
    "\t\t\tif(arguments.histEq == True):\n",
    "\t\t\t\timg =  histogramEqualization(img) \n",
    "\n",
    "\t\t\tlbp_value = local_binary_pattern(img, 8, 1)\n",
    "\n",
    "\t\t\t# Split img into 12*12 blocks (image size: 168 * 192)\n",
    "\t\t\tshaped = blockshaped(lbp_value, 16, 14)\n",
    "\n",
    "\t\t\t# Split img into 6*6 blocks (image size: 168 * 192)\n",
    "\t\t\t#shaped = blockshaped(lbp_value, 32, 28)\n",
    "\n",
    "\t\t\t# Split img into 3*3 blocks (image size: 168 * 192)\n",
    "\t\t\t#shaped = blockshaped(lbp_value, 64, 56)\n",
    "\n",
    "\t\t\t# Calculate the histogram for each block\n",
    "\t\t\txBlocks = []\n",
    "\t\t\tfor s in shaped:\n",
    "\t\t\t\txBlocks.append(getHistogram(s))\n",
    "\t\t\t# Concatenate the various histogram, the resulting histogram is append into feature vector\n",
    "\t\t\tx.append(numpy.concatenate(xBlocks))\n",
    "\n",
    "\t\t\t# if --output is passed as parameter\n",
    "\t\t\tif arguments.output == True:\n",
    "\t\t\t\tsaveImgLBP(getImgObjFromArray(lbp_value), arguments.dataset, filenames[counter], \"LBP\" )\n",
    "\n",
    "\t\t# If the image doens't exist\n",
    "\t\telse:\n",
    "\t\t\tprint(\"The image: \" + datasetFolder + xfp + \" doesn't exist\")\t\n",
    "\t\t# Add counter for new image\n",
    "\t\tcounter = counter + 1\n",
    "\n",
    "\n",
    "\tprint(\"--- LBP done in %s seconds ---\" % (time.time() - startTime))\n",
    "\n",
    "\tprint(\"Split dataset into training and test set [0.77] [0.33]\")\n",
    "\n",
    "\t# Split dataset x (feature vector) and y (label) into training and test set\n",
    "\txTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.33)\n",
    "\t\n",
    "\tprint(\"Launching \" + arguments.classifier.upper() + \"...\")\n",
    "\n",
    "\tstartTime = time.time()\n",
    "\n",
    "\tfilename = arguments.classifier + \".pkl\"\n",
    "\n",
    "\t# if --training is passet as parameter, perform the training of model\n",
    "\tif arguments.training == True:\n",
    "\t\ttrainingTime = time.time()\n",
    "\n",
    "\t\tif arguments.classifier == \"svm\": \n",
    "\t\t\tclf = svm.LinearSVC()\n",
    "\t\tif arguments.classifier == \"naivebayes\": \n",
    "\t\t\tclf = GaussianNB()\n",
    "\t\tif arguments.classifier == \"knn\": \n",
    "\t\t\tclf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\t\tprint(\"Start training...\")\n",
    "\t\tclf.fit(xTrain, yTrain)\n",
    "\t\tjoblib.dump(clf, 'model/' + filename) \n",
    "\t\tprint(\"--- Training done in %s seconds ---\" % (time.time() - trainingTime))\n",
    "\n",
    "\t# Test the model\n",
    "\tclf = joblib.load('model/' + filename) \n",
    "\tprint(\"Start testing...\")\n",
    "\tpredicted = clf.predict(xTest)\n",
    "\n",
    "\tprint(\"--- \" + arguments.classifier.upper() + \" done in %s seconds ---\" % (time.time() - startTime))\n",
    "\n",
    "\tprint(\"Accuracy: \" + str(accuracy_score(yTest, predicted)))\n",
    "\t\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d63176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "@author Andrea Corriga\n",
    "@contact me@andreacorriga.com\n",
    "@date 2018\n",
    "@version 1.0\n",
    "'''\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Import my alghorithms\n",
    "from algorithms.LBP import LBP\n",
    "# Import my utils method\n",
    "from utils.utils import *\n",
    "from utils.dataset import *\n",
    "\n",
    "from sklearn.metrics import accuracy_score #c alculate accuracy\n",
    "from sklearn.externals import joblib # save and load model\n",
    "from sklearn.model_selection import train_test_split # in order to split training and test\n",
    "import numpy\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "# Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "def main():\n",
    "\n",
    "\tparser = argparse.ArgumentParser(description='')\n",
    "\tparser.add_argument('--dataset', dest='dataset', type=str, default='YaleFaces', help='Main folder of the dataset')\n",
    "\tparser.add_argument('--classifier', dest='classifier', type=str, default='svm', help='Classifier to use: \"svm\" or \"naivebayes\" or \"knn\"')\n",
    "\tparser.add_argument('--training', dest='training', action='store_true', default=False, help='whether or not an output image should be produced')\n",
    "\tparser.add_argument('--histEq', dest='histEq', action='store_true', default=False, help='if you want to equialize the histogram before calculating LBP')\n",
    "\tparser.add_argument('--output', dest='output', action='store_true', default=False, help='if you want to save the png of LBP image')\n",
    "\n",
    "\targuments = parser.parse_args()\n",
    "\tdatasetMainFolder = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "\t# Security check about the classifier\n",
    "\tif(arguments.classifier != \"svm\" and arguments.classifier != \"naivebayes\" and arguments.classifier != \"knn\"):\n",
    "\t\tprint(\"Classifier not valid. Choose between svm, naivebayes or knn\")\n",
    "\t\treturn\n",
    "\n",
    "\t# Security check about the dataset\n",
    "\tif os.path.isdir(datasetMainFolder + arguments.dataset) == False:\n",
    "\t\tprint('The Dataset \"' + arguments.dataset + '\" doesn\\'t exist')\n",
    "\t\treturn\n",
    "\n",
    "\t# Helpful instad of write datasetMainFolder + arguments.dataset + \"/\"\n",
    "\tdatasetFolder = datasetMainFolder + arguments.dataset + \"/\"\n",
    "\n",
    "\t# Get Dataset information\n",
    "\tclasses, filenames, xFilepaths, y = getDataset(arguments.dataset)\n",
    "\tx = []\n",
    "\n",
    "\tprint(\"Launching LBP on the \" + arguments.dataset + \" dataset...\")\n",
    "\tstartTime = time.time()\n",
    "\n",
    "\t# This counter is used to store the png \n",
    "\tcounter = 0\n",
    "\n",
    "\t# if --output is passed as parameter\n",
    "\tif arguments.output == True:\n",
    "\t\tcreateFolderLBP(arguments.dataset, \"LBP\" )\n",
    "\n",
    "\n",
    "\tfor xfp in xFilepaths:\n",
    "\t\timg = imgRead(datasetFolder + xfp)\n",
    "\n",
    "\t\t#imgShow(numpy.matrix(img))\n",
    "\n",
    "\t\t# Check if img exist (security check)\n",
    "\t\tif img:\n",
    "\t\t\t# if --histEq is passed as parameter, perform an histogram equalization\n",
    "\t\t\tif(arguments.histEq == True):\n",
    "\t\t\t\timg =  histogramEqualization(img) \n",
    "\n",
    "\t\t\tlbp_value = local_binary_pattern(img, 8, 1)\n",
    "\n",
    "\t\t\t# Split img into 12*12 blocks (image size: 168 * 192)\n",
    "\t\t\tshaped = blockshaped(lbp_value, 16, 14)\n",
    "\n",
    "\t\t\t# Split img into 6*6 blocks (image size: 168 * 192)\n",
    "\t\t\t#shaped = blockshaped(lbp_value, 32, 28)\n",
    "\n",
    "\t\t\t# Split img into 3*3 blocks (image size: 168 * 192)\n",
    "\t\t\t#shaped = blockshaped(lbp_value, 64, 56)\n",
    "\n",
    "\t\t\t# Calculate the histogram for each block\n",
    "\t\t\txBlocks = []\n",
    "\t\t\tfor s in shaped:\n",
    "\t\t\t\txBlocks.append(getHistogram(s))\n",
    "\t\t\t# Concatenate the various histogram, the resulting histogram is append into feature vector\n",
    "\t\t\tx.append(numpy.concatenate(xBlocks))\n",
    "\n",
    "\t\t\t# if --output is passed as parameter\n",
    "\t\t\tif arguments.output == True:\n",
    "\t\t\t\tsaveImgLBP(getImgObjFromArray(lbp_value), arguments.dataset, filenames[counter], \"LBP\" )\n",
    "\n",
    "\t\t# If the image doens't exist\n",
    "\t\telse:\n",
    "\t\t\tprint(\"The image: \" + datasetFolder + xfp + \" doesn't exist\")\t\n",
    "\t\t# Add counter for new image\n",
    "\t\tcounter = counter + 1\n",
    "\n",
    "\n",
    "\tprint(\"--- LBP done in %s seconds ---\" % (time.time() - startTime))\n",
    "\n",
    "\tprint(\"Split dataset into training and test set [0.77] [0.33]\")\n",
    "\n",
    "\t# Split dataset x (feature vector) and y (label) into training and test set\n",
    "\txTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.33)\n",
    "\t\n",
    "\tprint(\"Launching \" + arguments.classifier.upper() + \"...\")\n",
    "\n",
    "\tstartTime = time.time()\n",
    "\n",
    "\tfilename = arguments.classifier + \".pkl\"\n",
    "\n",
    "\t# if --training is passet as parameter, perform the training of model\n",
    "\tif arguments.training == True:\n",
    "\t\ttrainingTime = time.time()\n",
    "\n",
    "\t\tif arguments.classifier == \"svm\": \n",
    "\t\t\tclf = svm.LinearSVC()\n",
    "\t\tif arguments.classifier == \"naivebayes\": \n",
    "\t\t\tclf = GaussianNB()\n",
    "\t\tif arguments.classifier == \"knn\": \n",
    "\t\t\tclf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "\t\tprint(\"Start training...\")\n",
    "\t\tclf.fit(xTrain, yTrain)\n",
    "\t\tjoblib.dump(clf, 'model/' + filename) \n",
    "\t\tprint(\"--- Training done in %s seconds ---\" % (time.time() - trainingTime))\n",
    "\n",
    "\t# Test the model\n",
    "\tclf = joblib.load('model/' + filename) \n",
    "\tprint(\"Start testing...\")\n",
    "\tpredicted = clf.predict(xTest)\n",
    "\n",
    "\tprint(\"--- \" + arguments.classifier.upper() + \" done in %s seconds ---\" % (time.time() - startTime))\n",
    "\n",
    "\tprint(\"Accuracy: \" + str(accuracy_score(yTest, predicted)))\n",
    "\t\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4714da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    }
   ],
   "source": [
    "pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db218dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
